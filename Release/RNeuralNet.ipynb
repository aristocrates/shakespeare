{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, LSTM\n",
    "\n",
    "import string\n",
    "from preprocessor import load_sonnets\n",
    "\n",
    "sonnets = load_sonnets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(string.ascii_lowercase)\n",
    "#chars = list(string.ascii_letters)\n",
    "chars += [\",\", \".\", \"?\", \"!\", \":\", \";\", \"'\", \"(\", \")\", \" \", \"\\n\", \"-\"]\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "train_strings = []\n",
    "char_length = 41\n",
    "char_skip = 3 #20\n",
    "\n",
    "for _, s in enumerate(sonnets):\n",
    "    #sonnet = \"\\n\".join(sonnets[0]).lower()\n",
    "    sonnet = \"\\n\".join(s).lower()\n",
    "    \n",
    "    for i in range(0, len(sonnet) - char_length, char_skip):\n",
    "        train_strings.append(sonnet[i: i+char_length])\n",
    "    #break\n",
    "    \n",
    "x = np.zeros((len(train_strings), char_length - 1, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_strings), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, train_string in enumerate(train_strings):\n",
    "    for t, char in enumerate(train_string[:-1]):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[train_string[-1]]] = 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 4,
>>>>>>> master
   "metadata": {},
   "outputs": [],
   "source": [
    "#timesteps = 8\n",
    "model = Sequential()\n",
    "#model.add(Dense(200, input_shape=(200,)))\n",
    "model.add(LSTM(200, input_shape=(char_length - 1, len(chars))))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 5,
>>>>>>> master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 2.7800 - acc: 0.2270\n",
      "Epoch 2/20\n",
      "29325/29325 [==============================] - 69s 2ms/step - loss: 2.2972 - acc: 0.3328\n",
      "Epoch 3/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 2.1422 - acc: 0.3719\n",
      "Epoch 4/20\n",
      "29325/29325 [==============================] - 69s 2ms/step - loss: 2.0395 - acc: 0.4000\n",
      "Epoch 5/20\n",
      "29325/29325 [==============================] - 68s 2ms/step - loss: 1.9516 - acc: 0.4224\n",
      "Epoch 6/20\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.8732 - acc: 0.4409\n",
      "Epoch 7/20\n",
      "29325/29325 [==============================] - 73s 3ms/step - loss: 1.8132 - acc: 0.4587\n",
      "Epoch 8/20\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.7525 - acc: 0.4712\n",
      "Epoch 9/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.6956 - acc: 0.4866\n",
      "Epoch 10/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.6457 - acc: 0.5005\n",
      "Epoch 11/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 1.5886 - acc: 0.5127\n",
      "Epoch 12/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.5321 - acc: 0.5285\n",
      "Epoch 13/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.4710 - acc: 0.5486\n",
      "Epoch 14/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.4067 - acc: 0.5670\n",
      "Epoch 15/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.3331 - acc: 0.5890\n",
      "Epoch 16/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.2600 - acc: 0.6117\n",
      "Epoch 17/20\n",
      "29325/29325 [==============================] - 75s 3ms/step - loss: 1.1805 - acc: 0.6347\n",
      "Epoch 18/20\n",
      "29325/29325 [==============================] - 85s 3ms/step - loss: 1.1013 - acc: 0.6623\n",
      "Epoch 19/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.0202 - acc: 0.6909\n",
      "Epoch 20/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 0.9400 - acc: 0.7152\n"
=======
      "Epoch 1/30\n",
      "29325/29325 [==============================] - 18s 600us/step - loss: 2.7539 - acc: 0.2263\n",
      "Epoch 2/30\n",
      "29325/29325 [==============================] - 17s 571us/step - loss: 2.2441 - acc: 0.3426\n",
      "Epoch 3/30\n",
      "29325/29325 [==============================] - 17s 573us/step - loss: 2.0696 - acc: 0.3898\n",
      "Epoch 4/30\n",
      "29325/29325 [==============================] - 17s 591us/step - loss: 1.9668 - acc: 0.4167\n",
      "Epoch 5/30\n",
      "29325/29325 [==============================] - 17s 586us/step - loss: 1.8798 - acc: 0.4376\n",
      "Epoch 6/30\n",
      "29325/29325 [==============================] - 17s 574us/step - loss: 1.8101 - acc: 0.4537\n",
      "Epoch 7/30\n",
      "29325/29325 [==============================] - 17s 576us/step - loss: 1.7413 - acc: 0.4711\n",
      "Epoch 8/30\n",
      "29325/29325 [==============================] - 17s 568us/step - loss: 1.6882 - acc: 0.4845\n",
      "Epoch 9/30\n",
      "29325/29325 [==============================] - 17s 568us/step - loss: 1.6337 - acc: 0.4977\n",
      "Epoch 10/30\n",
      "29325/29325 [==============================] - 17s 566us/step - loss: 1.5806 - acc: 0.5109\n",
      "Epoch 11/30\n",
      "29325/29325 [==============================] - 17s 567us/step - loss: 1.5248 - acc: 0.5244\n",
      "Epoch 12/30\n",
      "29325/29325 [==============================] - 18s 603us/step - loss: 1.4689 - acc: 0.5385\n",
      "Epoch 13/30\n",
      "29325/29325 [==============================] - 18s 597us/step - loss: 1.4040 - acc: 0.5552\n",
      "Epoch 14/30\n",
      "29325/29325 [==============================] - 17s 579us/step - loss: 1.3440 - acc: 0.5715\n",
      "Epoch 15/30\n",
      "29325/29325 [==============================] - 17s 577us/step - loss: 1.2737 - acc: 0.5922\n",
      "Epoch 16/30\n",
      "29325/29325 [==============================] - 17s 565us/step - loss: 1.2118 - acc: 0.6083\n",
      "Epoch 17/30\n",
      "29325/29325 [==============================] - 17s 564us/step - loss: 1.1393 - acc: 0.6287\n",
      "Epoch 18/30\n",
      "29325/29325 [==============================] - 17s 563us/step - loss: 1.0744 - acc: 0.6477\n",
      "Epoch 19/30\n",
      "29325/29325 [==============================] - 17s 563us/step - loss: 1.0030 - acc: 0.6682\n",
      "Epoch 20/30\n",
      "29325/29325 [==============================] - 16s 562us/step - loss: 0.9447 - acc: 0.6880\n",
      "Epoch 21/30\n",
      "29325/29325 [==============================] - 17s 579us/step - loss: 0.8855 - acc: 0.7081\n",
      "Epoch 22/30\n",
      "29325/29325 [==============================] - 18s 598us/step - loss: 0.8234 - acc: 0.7268\n",
      "Epoch 23/30\n",
      "29325/29325 [==============================] - 17s 574us/step - loss: 0.7738 - acc: 0.7456\n",
      "Epoch 24/30\n",
      "29325/29325 [==============================] - 18s 608us/step - loss: 0.7267 - acc: 0.7577\n",
      "Epoch 25/30\n",
      "29325/29325 [==============================] - 17s 584us/step - loss: 0.6789 - acc: 0.7720\n",
      "Epoch 26/30\n",
      "29325/29325 [==============================] - 17s 571us/step - loss: 0.6330 - acc: 0.7873\n",
      "Epoch 27/30\n",
      "29325/29325 [==============================] - 17s 593us/step - loss: 0.5928 - acc: 0.8001\n",
      "Epoch 28/30\n",
      "29325/29325 [==============================] - 17s 573us/step - loss: 0.5511 - acc: 0.8143\n",
      "Epoch 29/30\n",
      "29325/29325 [==============================] - 17s 573us/step - loss: 0.5153 - acc: 0.8292\n",
      "Epoch 30/30\n",
      "29325/29325 [==============================] - 17s 581us/step - loss: 0.4898 - acc: 0.8328\n"
>>>>>>> master
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<keras.callbacks.History at 0x1d8fb407518>"
      ]
     },
     "execution_count": 45,
=======
       "<keras.callbacks.History at 0x7f741d31a320>"
      ]
     },
     "execution_count": 5,
>>>>>>> master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.summary()\n",
<<<<<<< HEAD
    "model.fit(x, y, batch_size=64, epochs=20)"
=======
    "model.fit(x, y, batch_size=64, epochs=30)"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": 7,
>>>>>>> master
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmeyer/Documents/cs155/project3/tensorflow/lib64/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
<<<<<<< HEAD
      "that i have some thou desire thee mend,\n",
      "that of this gidce then thou lov's stays,\n",
      "  and i non this my out in pressed me,\n",
      "  in that the pleasure of this with the elles stall despain:\n",
      "the rast cons new vespech and beauty of thee,\n",
      "  then thou love's see,\n",
      "  but thou dest the sweet on the sun my sweat,\n",
      "not beck do plazing spest of this slive,\n",
      "the right fair that doth ckmen machire thee,\n",
      "me hourd of my self, nor thee i hath to geet,\n",
      "  thou apperition of thy my sughts the premont,\n",
      "which hate the words of that stould to be,\n",
      "  but i love's  and thee most can my self,\n",
      "though not the rectire of thy sweet strong,\n",
=======
      "the whry of her you with thy living thee,\n",
      "o thy self thy self aw reserved to show,\n",
      "they douncessed excue the know my heart in the.\n",
      "o must leave and way thy beauty thou mood,\n",
      "  and my heart thee thoughts, or why seffece,\n",
      "when i (my sone but love, on the ward,\n",
      "and the fimmert stand in heart's still,\n",
      "for anour and sweet repubing that he vee.\n",
      "f the wart not be thou love thy will,\n",
      "and beauty's lies and the gard to making,\n",
      "and that i mise see self-tiandot wanderest love,\n",
      "a moning tan thee i my love thee relity,\n",
      "no reast that with each sweet reloved,\n",
      "  maning so mresink can beas not came, decrowitk's vile,\n",
>>>>>>> master
      "\n"
     ]
    }
   ],
   "source": [
    "# Function equivalent to below\n",
    "def generate_poem(seed = \"shall i compare thee to a summer's day?\\n\", lines=14):\n",
    "    generated = \"\" + seed\n",
    "\n",
    "    # Generates 14 lines of poem\n",
    "    \n",
    "    for i in range(lines):\n",
    "        while True:\n",
    "            x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "            for t, char in enumerate(seed):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "            next_index = sample(preds, temperature=0.5)\n",
    "            next_char = indices_char[next_index]\n",
    "            seed = seed[1:] + next_char\n",
    "        \n",
    "            generated += next_char\n",
    "            if next_char == \"\\n\":\n",
    "                #print(generated)\n",
    "                #generated = \"\"\n",
    "                break\n",
    "            #generated += next_char\n",
    "\n",
    "    return generated\n",
    "    \n",
    "print(generate_poem())\n",
    "\n",
    "'''\n",
    "\n",
    "shall i compare thee to a summer's day?\n",
    "the praise the praise the reauted from thee,\n",
    "but thou dest that songsed in thy reast changer\n",
    "even to be more with thou mestresss dast sack of bord's new,\n",
    "and stall dest in my dove them farren,\n",
    "when i sey a selfer tean heart thou sood,\n",
    "on the thou art and for my seathons spead,\n",
    "but mine ow spest of your sild praise,\n",
    "shang on my live and praises if that i not,\n",
    "  but thou less it lives beauty's gaine,\n",
    "when is she whor my life it me do bles,\n",
    "though thy that is the tome, the recoor fir my prais,\n",
    "but there my solf love so my love the wrent,\n",
    "excessed thy frast with thy beture then leave,\n",
    "that more preaute of the restorn love and grave,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
=======
   "execution_count": 8,
>>>>>>> master
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmeyer/Documents/cs155/project3/tensorflow/lib64/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
<<<<<<< HEAD
      "the ore wo das words on thy sweet love still,\n",
      "though thy love ast speaking shall the rest,\n",
      "why i me do thee mayst chought of thy love,\n",
      "and stay the report of mort fair thou presse,\n",
      "the wirnt thou art that is the pless of tind,\n",
      "  and the thy banter that the sur oft so,\n",
      "and that i have so my love thee my lie:\n",
      "the sun i contant of this swill stand\n",
      "the show thy sweet streace the sweet strings,\n",
      "  thou and the strong to fair thou art and speak,\n",
      "the summer end hath that she should to be,\n",
      "the wiented that the store thou art and prave,\n",
      "that in the surmer in my self in liess be ong that i am stall,\n",
      "bet by a det an my blath that in the sweet,\n",
=======
      "thy sweal see to me sure, and the wear weel,\n",
      "  and in purse,\n",
      "one pitterne make than blage recore:\n",
      "the ward the plyis of you wist me self thy well,\n",
      "that i (our so love, nor thy will be thee,\n",
      "  you hastur thin, it see and troamere of my seath,\n",
      "which then desire, the well rary thee there,\n",
      "the see thy self thy menure of mearth's my days my say,\n",
      "even wither belonced tongursed of proand,\n",
      "and many heart beloved to bust, all be,\n",
      "but in the beauty that my hade on me thath,\n",
      "and sienct my frouthes in thy self to sigut,\n",
      "and make as thine or thine, he vounst of thee,\n",
      "  that dishervel noth which in a sen thee,\n",
>>>>>>> master
      "\n"
     ]
    }
   ],
   "source": [
    "#seed = \"shall i compare thee to a summer's day?\\nthou art more lovely\"\n",
    "seed = \"shall i compare thee to a summer's day?\\n\"\n",
    "generated = \"\" + seed\n",
    "\n",
    "# Generates 14 lines of poem (More efficient)\n",
    "\n",
    "x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "for t, char in enumerate(seed):\n",
    "    x_pred[0, t, char_indices[char]] = 1.\n",
    "preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "for i in range(14):\n",
    "    while True:\n",
    "        next_index = sample(preds, temperature=0.2)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        x_pred[0, :-1, :] = x_pred[:, 1:, :]\n",
    "        x_pred[0, -1, :] = np.zeros(len(chars))\n",
    "        x_pred[0, -1, char_indices[next_char]] = 1.\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        generated += next_char\n",
    "        if next_char == \"\\n\":\n",
    "            #print(generated)\n",
    "            #generated = \"\"\n",
    "            break\n",
    "        #generated += next_char\n",
    "        \n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29325, 38)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "#print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
