{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, LSTM\n",
    "\n",
    "import string\n",
    "from preprocessor import load_sonnets\n",
    "\n",
    "sonnets = load_sonnets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = list(string.ascii_lowercase)\n",
    "#chars = list(string.ascii_letters)\n",
    "chars += [\",\", \".\", \"?\", \"!\", \":\", \";\", \"'\", \"(\", \")\", \" \", \"\\n\", \"-\"]\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "train_strings = []\n",
    "char_length = 41\n",
    "char_skip = 3 #20\n",
    "\n",
    "for _, s in enumerate(sonnets):\n",
    "    #sonnet = \"\\n\".join(sonnets[0]).lower()\n",
    "    sonnet = \"\\n\".join(s).lower()\n",
    "    \n",
    "    for i in range(0, len(sonnet) - char_length, char_skip):\n",
    "        train_strings.append(sonnet[i: i+char_length])\n",
    "    #break\n",
    "    \n",
    "x = np.zeros((len(train_strings), char_length - 1, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_strings), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, train_string in enumerate(train_strings):\n",
    "    for t, char in enumerate(train_string[:-1]):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[train_string[-1]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timesteps = 8\n",
    "model = Sequential()\n",
    "#model.add(Dense(200, input_shape=(200,)))\n",
    "model.add(LSTM(200, input_shape=(char_length - 1, len(chars))))\n",
    "#model.add(Dense(200))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 2.7800 - acc: 0.2270\n",
      "Epoch 2/20\n",
      "29325/29325 [==============================] - 69s 2ms/step - loss: 2.2972 - acc: 0.3328\n",
      "Epoch 3/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 2.1422 - acc: 0.3719\n",
      "Epoch 4/20\n",
      "29325/29325 [==============================] - 69s 2ms/step - loss: 2.0395 - acc: 0.4000\n",
      "Epoch 5/20\n",
      "29325/29325 [==============================] - 68s 2ms/step - loss: 1.9516 - acc: 0.4224\n",
      "Epoch 6/20\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.8732 - acc: 0.4409\n",
      "Epoch 7/20\n",
      "29325/29325 [==============================] - 73s 3ms/step - loss: 1.8132 - acc: 0.4587\n",
      "Epoch 8/20\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.7525 - acc: 0.4712\n",
      "Epoch 9/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.6956 - acc: 0.4866\n",
      "Epoch 10/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.6457 - acc: 0.5005\n",
      "Epoch 11/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 1.5886 - acc: 0.5127\n",
      "Epoch 12/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.5321 - acc: 0.5285\n",
      "Epoch 13/20\n",
      "29325/29325 [==============================] - 73s 2ms/step - loss: 1.4710 - acc: 0.5486\n",
      "Epoch 14/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.4067 - acc: 0.5670\n",
      "Epoch 15/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.3331 - acc: 0.5890\n",
      "Epoch 16/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.2600 - acc: 0.6117\n",
      "Epoch 17/20\n",
      "29325/29325 [==============================] - 75s 3ms/step - loss: 1.1805 - acc: 0.6347\n",
      "Epoch 18/20\n",
      "29325/29325 [==============================] - 85s 3ms/step - loss: 1.1013 - acc: 0.6623\n",
      "Epoch 19/20\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 1.0202 - acc: 0.6909\n",
      "Epoch 20/20\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 0.9400 - acc: 0.7152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8fb407518>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.summary()\n",
    "model.fit(x, y, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "that i have some thou desire thee mend,\n",
      "that of this gidce then thou lov's stays,\n",
      "  and i non this my out in pressed me,\n",
      "  in that the pleasure of this with the elles stall despain:\n",
      "the rast cons new vespech and beauty of thee,\n",
      "  then thou love's see,\n",
      "  but thou dest the sweet on the sun my sweat,\n",
      "not beck do plazing spest of this slive,\n",
      "the right fair that doth ckmen machire thee,\n",
      "me hourd of my self, nor thee i hath to geet,\n",
      "  thou apperition of thy my sughts the premont,\n",
      "which hate the words of that stould to be,\n",
      "  but i love's  and thee most can my self,\n",
      "though not the rectire of thy sweet strong,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function equivalent to below\n",
    "def generate_poem(seed = \"shall i compare thee to a summer's day?\\n\", lines=14):\n",
    "    generated = \"\" + seed\n",
    "\n",
    "    # Generates 14 lines of poem\n",
    "    \n",
    "    for i in range(lines):\n",
    "        while True:\n",
    "            x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "            for t, char in enumerate(seed):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "            next_index = sample(preds, temperature=0.5)\n",
    "            next_char = indices_char[next_index]\n",
    "            seed = seed[1:] + next_char\n",
    "        \n",
    "            generated += next_char\n",
    "            if next_char == \"\\n\":\n",
    "                #print(generated)\n",
    "                #generated = \"\"\n",
    "                break\n",
    "            #generated += next_char\n",
    "\n",
    "    return generated\n",
    "    \n",
    "print(generate_poem())\n",
    "\n",
    "'''\n",
    "\n",
    "shall i compare thee to a summer's day?\n",
    "the praise the praise the reauted from thee,\n",
    "but thou dest that songsed in thy reast changer\n",
    "even to be more with thou mestresss dast sack of bord's new,\n",
    "and stall dest in my dove them farren,\n",
    "when i sey a selfer tean heart thou sood,\n",
    "on the thou art and for my seathons spead,\n",
    "but mine ow spest of your sild praise,\n",
    "shang on my live and praises if that i not,\n",
    "  but thou less it lives beauty's gaine,\n",
    "when is she whor my life it me do bles,\n",
    "though thy that is the tome, the recoor fir my prais,\n",
    "but there my solf love so my love the wrent,\n",
    "excessed thy frast with thy beture then leave,\n",
    "that more preaute of the restorn love and grave,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "the ore wo das words on thy sweet love still,\n",
      "though thy love ast speaking shall the rest,\n",
      "why i me do thee mayst chought of thy love,\n",
      "and stay the report of mort fair thou presse,\n",
      "the wirnt thou art that is the pless of tind,\n",
      "  and the thy banter that the sur oft so,\n",
      "and that i have so my love thee my lie:\n",
      "the sun i contant of this swill stand\n",
      "the show thy sweet streace the sweet strings,\n",
      "  thou and the strong to fair thou art and speak,\n",
      "the summer end hath that she should to be,\n",
      "the wiented that the store thou art and prave,\n",
      "that in the surmer in my self in liess be ong that i am stall,\n",
      "bet by a det an my blath that in the sweet,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#seed = \"shall i compare thee to a summer's day?\\nthou art more lovely\"\n",
    "seed = \"shall i compare thee to a summer's day?\\n\"\n",
    "generated = \"\" + seed\n",
    "\n",
    "# Generates 14 lines of poem (More efficient)\n",
    "\n",
    "x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "for t, char in enumerate(seed):\n",
    "    x_pred[0, t, char_indices[char]] = 1.\n",
    "preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "for i in range(14):\n",
    "    while True:\n",
    "        next_index = sample(preds, temperature=0.2)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        x_pred[0, :-1, :] = x_pred[:, 1:, :]\n",
    "        x_pred[0, -1, :] = np.zeros(len(chars))\n",
    "        x_pred[0, -1, char_indices[next_char]] = 1.\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        generated += next_char\n",
    "        if next_char == \"\\n\":\n",
    "            #print(generated)\n",
    "            #generated = \"\"\n",
    "            break\n",
    "        #generated += next_char\n",
    "        \n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29325, 38)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "#print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
