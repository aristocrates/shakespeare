{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, LSTM\n",
    "\n",
    "import string\n",
    "from preprocessor import load_sonnets\n",
    "\n",
    "sonnets = load_sonnets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = list(string.ascii_lowercase)\n",
    "#chars = list(string.ascii_letters)\n",
    "chars += [\",\", \".\", \"?\", \"!\", \":\", \";\", \"'\", \"(\", \")\", \" \", \"\\n\", \"-\"]\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "train_strings = []\n",
    "char_length = 41\n",
    "char_skip = 3 #20\n",
    "\n",
    "for _, s in enumerate(sonnets):\n",
    "    #sonnet = \"\\n\".join(sonnets[0]).lower()\n",
    "    sonnet = \"\\n\".join(s).lower()\n",
    "    \n",
    "    for i in range(0, len(sonnet) - char_length, char_skip):\n",
    "        train_strings.append(sonnet[i: i+char_length])\n",
    "    #break\n",
    "    \n",
    "x = np.zeros((len(train_strings), char_length - 1, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_strings), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, train_string in enumerate(train_strings):\n",
    "    for t, char in enumerate(train_string[:-1]):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[train_string[-1]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timesteps = 8\n",
    "model = Sequential()\n",
    "#model.add(Dense(200, input_shape=(200,)))\n",
    "model.add(LSTM(200, input_shape=(char_length - 1, len(chars))))\n",
    "#model.add(Dense(200))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29325/29325 [==============================] - 75s 3ms/step - loss: 2.7564 - acc: 0.2334\n",
      "Epoch 2/10\n",
      "29325/29325 [==============================] - 80s 3ms/step - loss: 2.2884 - acc: 0.3380\n",
      "Epoch 3/10\n",
      "29325/29325 [==============================] - 76s 3ms/step - loss: 2.1240 - acc: 0.3771\n",
      "Epoch 4/10\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 2.0084 - acc: 0.4093\n",
      "Epoch 5/10\n",
      "29325/29325 [==============================] - 70s 2ms/step - loss: 1.9258 - acc: 0.4290\n",
      "Epoch 6/10\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.8573 - acc: 0.4478\n",
      "Epoch 7/10\n",
      "29325/29325 [==============================] - 72s 2ms/step - loss: 1.7966 - acc: 0.4612\n",
      "Epoch 8/10\n",
      "29325/29325 [==============================] - 80s 3ms/step - loss: 1.7417 - acc: 0.4754: 4s - \n",
      "Epoch 9/10\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 1.6867 - acc: 0.4900\n",
      "Epoch 10/10\n",
      "29325/29325 [==============================] - 74s 3ms/step - loss: 1.6343 - acc: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8ff331048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.summary()\n",
    "model.fit(x, y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "the beauty my seeftee the windst thee,\n",
      "  the beest thou art of the gainty wert,\n",
      "  the pairt the reast the seast thy love,\n",
      "the prease the tore then the canlled,\n",
      "and the tore-to ene thy wall thy sunded in\n",
      "the sumer,\n",
      "then a see the elest beautes that then the reast,\n",
      "  for of the sull whe sone me prowing thines,\n",
      "that me i me seade the seef the  im looks no now,\n",
      "but the the the tround hand the tore then thee,\n",
      "  the ofrect on the proust thy self to the prow,\n",
      "that the tere, of the deer mayst is see.\n",
      "  that i hall stain the seet the sweet in thee,\n",
      "  the confore the hanger so thou soulded,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_poem(seed = \"shall i compare thee to a summer's day?\\n\", lines=14):\n",
    "    generated = \"\" + seed\n",
    "\n",
    "    # Generates 14 lines of poem\n",
    "    \n",
    "    for i in range(lines):\n",
    "        while True:\n",
    "            x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "            for t, char in enumerate(seed):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "            next_index = sample(preds, temperature=0.5)\n",
    "            next_char = indices_char[next_index]\n",
    "            seed = seed[1:] + next_char\n",
    "        \n",
    "            generated += next_char\n",
    "            if next_char == \"\\n\":\n",
    "                #print(generated)\n",
    "                #generated = \"\"\n",
    "                break\n",
    "            #generated += next_char\n",
    "\n",
    "    print(generated)\n",
    "    \n",
    "generate_poem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "but the with thy beauthers my so for mine,\n",
      "the days the rach thou thy self the rearted to the thee,\n",
      "of the senfless chert of the love,\n",
      "that in the parst the seare the wainst my seare.\n",
      "  be your that i she hall still be of thee,\n",
      "the forther then me that can the raysh thee thought,\n",
      "the farse the reast bether that fer the still,\n",
      "the looks my self-tored hand of tho gaik,\n",
      "the hald with that it the paint the will,\n",
      "o searing all i lave your my beauty,\n",
      "the ald thy sulfer wathen thy self the see,\n",
      "the thence,\n",
      "the sur the parsed no brieg to tree,\n",
      "  so more nom the seathen see the reart,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#seed = \"shall i compare thee to a summer's day?\\nthou art more lovely\"\n",
    "seed = \"shall i compare thee to a summer's day?\\n\"\n",
    "generated = \"\" + seed\n",
    "\n",
    "# Generates 14 lines of poem (More efficient)\n",
    "\n",
    "x_pred = np.zeros((1, char_length - 1, len(chars)))\n",
    "for t, char in enumerate(seed):\n",
    "    x_pred[0, t, char_indices[char]] = 1.\n",
    "preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "for i in range(14):\n",
    "    while True:\n",
    "        next_index = sample(preds, temperature=0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        x_pred[0, :-1, :] = x_pred[:, 1:, :]\n",
    "        x_pred[0, -1, :] = np.zeros(len(chars))\n",
    "        x_pred[0, -1, char_indices[next_char]] = 1.\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        generated += next_char\n",
    "        if next_char == \"\\n\":\n",
    "            #print(generated)\n",
    "            #generated = \"\"\n",
    "            break\n",
    "        #generated += next_char\n",
    "        \n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29325, 38)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "#print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
